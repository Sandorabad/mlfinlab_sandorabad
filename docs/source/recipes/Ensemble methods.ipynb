{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In data science world, _Bootstrap aggregation(bagging)_ is a one of wonderful skills to get a better performance within the limited data. The advantage of using Bagging lays in its ability to reduce forecast variance and thus prevents overfitting. However, we know that financial observations cannot be simply assumed to be IID. If we don't address that issue carefully, we can not fully take advantage of the benefits of the bagging. Through mlfinlab package, We can navigate the bagging process in finance by leveraging [sklearn](https://scikit-learn.org)'s `BaggingClassifier/Regressor` with [seq_bootstrap](https://mlfinlab.readthedocs.io/en/latest/implementations/sampling.html#mlfinlab.sampling.bootstrapping.seq_bootstrap).\n",
    "\n",
    "\n",
    "Let's check how we can use _random forest_ algorithm and _sequential bootstrap_ in the _mlfinlab_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import mlfinlab as ml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>cum_vol</th>\n",
       "      <th>cum_dollar</th>\n",
       "      <th>cum_ticks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04 01:17:36.863</th>\n",
       "      <td>2036.50</td>\n",
       "      <td>2043.50</td>\n",
       "      <td>2034.75</td>\n",
       "      <td>2040.50</td>\n",
       "      <td>34337</td>\n",
       "      <td>70002505.75</td>\n",
       "      <td>5587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 03:26:50.833</th>\n",
       "      <td>2040.50</td>\n",
       "      <td>2041.75</td>\n",
       "      <td>2025.75</td>\n",
       "      <td>2031.25</td>\n",
       "      <td>34443</td>\n",
       "      <td>70003995.50</td>\n",
       "      <td>8520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 06:17:16.453</th>\n",
       "      <td>2031.25</td>\n",
       "      <td>2032.75</td>\n",
       "      <td>2016.00</td>\n",
       "      <td>2016.00</td>\n",
       "      <td>34654</td>\n",
       "      <td>70077289.00</td>\n",
       "      <td>9943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 08:07:12.320</th>\n",
       "      <td>2016.25</td>\n",
       "      <td>2019.25</td>\n",
       "      <td>2007.50</td>\n",
       "      <td>2007.75</td>\n",
       "      <td>34800</td>\n",
       "      <td>70063062.25</td>\n",
       "      <td>7853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 08:47:15.283</th>\n",
       "      <td>2007.75</td>\n",
       "      <td>2007.75</td>\n",
       "      <td>2001.00</td>\n",
       "      <td>2005.25</td>\n",
       "      <td>34939</td>\n",
       "      <td>70026656.00</td>\n",
       "      <td>7407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 20:00:03.168</th>\n",
       "      <td>2090.50</td>\n",
       "      <td>2090.75</td>\n",
       "      <td>2087.25</td>\n",
       "      <td>2089.00</td>\n",
       "      <td>33527</td>\n",
       "      <td>70036244.50</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 20:00:54.844</th>\n",
       "      <td>2089.00</td>\n",
       "      <td>2089.25</td>\n",
       "      <td>2087.25</td>\n",
       "      <td>2087.75</td>\n",
       "      <td>33593</td>\n",
       "      <td>70148391.25</td>\n",
       "      <td>1935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 20:05:54.542</th>\n",
       "      <td>2087.50</td>\n",
       "      <td>2087.75</td>\n",
       "      <td>2086.25</td>\n",
       "      <td>2087.00</td>\n",
       "      <td>33725</td>\n",
       "      <td>70377246.25</td>\n",
       "      <td>2538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 20:13:58.349</th>\n",
       "      <td>2087.00</td>\n",
       "      <td>2089.25</td>\n",
       "      <td>2086.25</td>\n",
       "      <td>2088.50</td>\n",
       "      <td>33544</td>\n",
       "      <td>70033735.00</td>\n",
       "      <td>2612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 22:10:16.308</th>\n",
       "      <td>2088.75</td>\n",
       "      <td>2088.75</td>\n",
       "      <td>2085.50</td>\n",
       "      <td>2086.50</td>\n",
       "      <td>33532</td>\n",
       "      <td>70001796.00</td>\n",
       "      <td>3220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6556 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            open     high      low    close  cum_vol  \\\n",
       "date_time                                                              \n",
       "2016-01-04 01:17:36.863  2036.50  2043.50  2034.75  2040.50    34337   \n",
       "2016-01-04 03:26:50.833  2040.50  2041.75  2025.75  2031.25    34443   \n",
       "2016-01-04 06:17:16.453  2031.25  2032.75  2016.00  2016.00    34654   \n",
       "2016-01-04 08:07:12.320  2016.25  2019.25  2007.50  2007.75    34800   \n",
       "2016-01-04 08:47:15.283  2007.75  2007.75  2001.00  2005.25    34939   \n",
       "...                          ...      ...      ...      ...      ...   \n",
       "2016-06-30 20:00:03.168  2090.50  2090.75  2087.25  2089.00    33527   \n",
       "2016-06-30 20:00:54.844  2089.00  2089.25  2087.25  2087.75    33593   \n",
       "2016-06-30 20:05:54.542  2087.50  2087.75  2086.25  2087.00    33725   \n",
       "2016-06-30 20:13:58.349  2087.00  2089.25  2086.25  2088.50    33544   \n",
       "2016-06-30 22:10:16.308  2088.75  2088.75  2085.50  2086.50    33532   \n",
       "\n",
       "                          cum_dollar  cum_ticks  \n",
       "date_time                                        \n",
       "2016-01-04 01:17:36.863  70002505.75       5587  \n",
       "2016-01-04 03:26:50.833  70003995.50       8520  \n",
       "2016-01-04 06:17:16.453  70077289.00       9943  \n",
       "2016-01-04 08:07:12.320  70063062.25       7853  \n",
       "2016-01-04 08:47:15.283  70026656.00       7407  \n",
       "...                              ...        ...  \n",
       "2016-06-30 20:00:03.168  70036244.50       1495  \n",
       "2016-06-30 20:00:54.844  70148391.25       1935  \n",
       "2016-06-30 20:05:54.542  70377246.25       2538  \n",
       "2016-06-30 20:13:58.349  70033735.00       2612  \n",
       "2016-06-30 22:10:16.308  70001796.00       3220  \n",
       "\n",
       "[6556 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dollar_bars.csv', nrows=40000)\n",
    "data.index = pd.to_datetime(data['date_time'])\n",
    "data = data.drop('date_time', axis=1)\n",
    "data = data.loc['2016-01-01':'2016-06-30']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make meta-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate RSI and Bollinger bands for side-preidcition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RSI\n",
    "def relative_strength_index(df, n):\n",
    "        \"\"\"Calculate Relative Strength Index(RSI) for given data.\n",
    "        https://github.com/Crypto-toolbox/pandas-technical-indicators/blob/master/technical_indicators.py\n",
    "        \n",
    "        :param df: pandas.DataFrame\n",
    "        :param n: \n",
    "        :return: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        i = 0\n",
    "        UpI = [0]\n",
    "        DoI = [0]\n",
    "        while i + 1 <= df.index[-1]:\n",
    "            UpMove = df.loc[i + 1, 'high'] - df.loc[i, 'high']\n",
    "            DoMove = df.loc[i, 'low'] - df.loc[i + 1, 'low']\n",
    "            if UpMove > DoMove and UpMove > 0:\n",
    "                UpD = UpMove\n",
    "            else:\n",
    "                UpD = 0\n",
    "            UpI.append(UpD)\n",
    "            if DoMove > UpMove and DoMove > 0:\n",
    "                DoD = DoMove\n",
    "            else:\n",
    "                DoD = 0\n",
    "            DoI.append(DoD)\n",
    "            i = i + 1\n",
    "        UpI = pd.Series(UpI)\n",
    "        DoI = pd.Series(DoI)\n",
    "        PosDI = pd.Series(UpI.ewm(span=n, min_periods=n).mean())\n",
    "        NegDI = pd.Series(DoI.ewm(span=n, min_periods=n).mean())\n",
    "        RSI = pd.Series(round(PosDI * 100. / (PosDI + NegDI)), name='RSI_' + str(n))\n",
    "        # df = df.join(RSI)\n",
    "        return RSI\n",
    "\n",
    "def get_rsi(data, window=14):\n",
    "    df = data.copy(deep=True).reset_index()\n",
    "    rsi = relative_strength_index(df, window)\n",
    "    rsi_df = pd.Series(data=rsi.values, index=data.index)\n",
    "    return rsi_df\n",
    "\n",
    "\n",
    "def bbands(close_prices, window, no_of_stdev):\n",
    "    rolling_mean = close_prices.ewm(span=window).mean()\n",
    "    rolling_std = close_prices.ewm(span=window).std()\n",
    "\n",
    "    upper_band = rolling_mean + (rolling_std * no_of_stdev)\n",
    "    lower_band = rolling_mean - (rolling_std * no_of_stdev)\n",
    "\n",
    "    return rolling_mean, upper_band, lower_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>cum_vol</th>\n",
       "      <th>cum_dollar</th>\n",
       "      <th>cum_ticks</th>\n",
       "      <th>avg</th>\n",
       "      <th>upper</th>\n",
       "      <th>lower</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-06 19:55:54.770</th>\n",
       "      <td>2109.75</td>\n",
       "      <td>2109.75</td>\n",
       "      <td>2107.75</td>\n",
       "      <td>2108.75</td>\n",
       "      <td>33385</td>\n",
       "      <td>70394214.00</td>\n",
       "      <td>2749</td>\n",
       "      <td>2103.598324</td>\n",
       "      <td>2112.991362</td>\n",
       "      <td>2094.205286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-02 13:38:48.661</th>\n",
       "      <td>2090.75</td>\n",
       "      <td>2093.00</td>\n",
       "      <td>2090.25</td>\n",
       "      <td>2092.50</td>\n",
       "      <td>33468</td>\n",
       "      <td>70002268.75</td>\n",
       "      <td>3664</td>\n",
       "      <td>2093.505030</td>\n",
       "      <td>2098.691578</td>\n",
       "      <td>2088.318482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-29 13:47:47.706</th>\n",
       "      <td>2063.75</td>\n",
       "      <td>2065.75</td>\n",
       "      <td>2061.00</td>\n",
       "      <td>2062.00</td>\n",
       "      <td>33989</td>\n",
       "      <td>70115080.75</td>\n",
       "      <td>4038</td>\n",
       "      <td>2073.318252</td>\n",
       "      <td>2086.512625</td>\n",
       "      <td>2060.123878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-25 18:10:00.893</th>\n",
       "      <td>1889.50</td>\n",
       "      <td>1895.00</td>\n",
       "      <td>1888.00</td>\n",
       "      <td>1894.00</td>\n",
       "      <td>37005</td>\n",
       "      <td>70000155.00</td>\n",
       "      <td>5526</td>\n",
       "      <td>1890.166744</td>\n",
       "      <td>1900.892090</td>\n",
       "      <td>1879.441397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-24 20:23:40.438</th>\n",
       "      <td>1926.75</td>\n",
       "      <td>1928.00</td>\n",
       "      <td>1925.25</td>\n",
       "      <td>1925.75</td>\n",
       "      <td>36331</td>\n",
       "      <td>70000420.00</td>\n",
       "      <td>4198</td>\n",
       "      <td>1909.042127</td>\n",
       "      <td>1927.300922</td>\n",
       "      <td>1890.783331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-08 14:41:13.169</th>\n",
       "      <td>1842.00</td>\n",
       "      <td>1844.75</td>\n",
       "      <td>1841.00</td>\n",
       "      <td>1844.75</td>\n",
       "      <td>38020</td>\n",
       "      <td>70054715.25</td>\n",
       "      <td>5135</td>\n",
       "      <td>1868.609889</td>\n",
       "      <td>1895.789249</td>\n",
       "      <td>1841.430529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-28 12:07:52.417</th>\n",
       "      <td>1878.25</td>\n",
       "      <td>1878.50</td>\n",
       "      <td>1872.00</td>\n",
       "      <td>1874.00</td>\n",
       "      <td>37346</td>\n",
       "      <td>70035667.50</td>\n",
       "      <td>7917</td>\n",
       "      <td>1883.486716</td>\n",
       "      <td>1899.585584</td>\n",
       "      <td>1867.387847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-11 16:24:08.067</th>\n",
       "      <td>1814.75</td>\n",
       "      <td>1818.75</td>\n",
       "      <td>1812.25</td>\n",
       "      <td>1812.50</td>\n",
       "      <td>38549</td>\n",
       "      <td>70005751.25</td>\n",
       "      <td>5426</td>\n",
       "      <td>1827.744991</td>\n",
       "      <td>1852.732962</td>\n",
       "      <td>1802.757021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-20 00:37:06.745</th>\n",
       "      <td>2038.25</td>\n",
       "      <td>2042.00</td>\n",
       "      <td>2037.25</td>\n",
       "      <td>2042.00</td>\n",
       "      <td>34343</td>\n",
       "      <td>70026738.75</td>\n",
       "      <td>4510</td>\n",
       "      <td>2033.637470</td>\n",
       "      <td>2042.817151</td>\n",
       "      <td>2024.457790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-04 15:22:31.659</th>\n",
       "      <td>2045.50</td>\n",
       "      <td>2046.00</td>\n",
       "      <td>2042.00</td>\n",
       "      <td>2042.75</td>\n",
       "      <td>34267</td>\n",
       "      <td>70039705.25</td>\n",
       "      <td>4328</td>\n",
       "      <td>2050.794783</td>\n",
       "      <td>2060.959481</td>\n",
       "      <td>2040.630086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            open     high      low    close  cum_vol  \\\n",
       "date_time                                                              \n",
       "2016-06-06 19:55:54.770  2109.75  2109.75  2107.75  2108.75    33385   \n",
       "2016-06-02 13:38:48.661  2090.75  2093.00  2090.25  2092.50    33468   \n",
       "2016-04-29 13:47:47.706  2063.75  2065.75  2061.00  2062.00    33989   \n",
       "2016-01-25 18:10:00.893  1889.50  1895.00  1888.00  1894.00    37005   \n",
       "2016-02-24 20:23:40.438  1926.75  1928.00  1925.25  1925.75    36331   \n",
       "2016-02-08 14:41:13.169  1842.00  1844.75  1841.00  1844.75    38020   \n",
       "2016-01-28 12:07:52.417  1878.25  1878.50  1872.00  1874.00    37346   \n",
       "2016-02-11 16:24:08.067  1814.75  1818.75  1812.25  1812.50    38549   \n",
       "2016-05-20 00:37:06.745  2038.25  2042.00  2037.25  2042.00    34343   \n",
       "2016-05-04 15:22:31.659  2045.50  2046.00  2042.00  2042.75    34267   \n",
       "\n",
       "                          cum_dollar  cum_ticks          avg        upper  \\\n",
       "date_time                                                                   \n",
       "2016-06-06 19:55:54.770  70394214.00       2749  2103.598324  2112.991362   \n",
       "2016-06-02 13:38:48.661  70002268.75       3664  2093.505030  2098.691578   \n",
       "2016-04-29 13:47:47.706  70115080.75       4038  2073.318252  2086.512625   \n",
       "2016-01-25 18:10:00.893  70000155.00       5526  1890.166744  1900.892090   \n",
       "2016-02-24 20:23:40.438  70000420.00       4198  1909.042127  1927.300922   \n",
       "2016-02-08 14:41:13.169  70054715.25       5135  1868.609889  1895.789249   \n",
       "2016-01-28 12:07:52.417  70035667.50       7917  1883.486716  1899.585584   \n",
       "2016-02-11 16:24:08.067  70005751.25       5426  1827.744991  1852.732962   \n",
       "2016-05-20 00:37:06.745  70026738.75       4510  2033.637470  2042.817151   \n",
       "2016-05-04 15:22:31.659  70039705.25       4328  2050.794783  2060.959481   \n",
       "\n",
       "                               lower  \n",
       "date_time                             \n",
       "2016-06-06 19:55:54.770  2094.205286  \n",
       "2016-06-02 13:38:48.661  2088.318482  \n",
       "2016-04-29 13:47:47.706  2060.123878  \n",
       "2016-01-25 18:10:00.893  1879.441397  \n",
       "2016-02-24 20:23:40.438  1890.783331  \n",
       "2016-02-08 14:41:13.169  1841.430529  \n",
       "2016-01-28 12:07:52.417  1867.387847  \n",
       "2016-02-11 16:24:08.067  1802.757021  \n",
       "2016-05-20 00:37:06.745  2024.457790  \n",
       "2016-05-04 15:22:31.659  2040.630086  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute bands\n",
    "window = 50\n",
    "data['avg'], data['upper'], data['lower'] = bbands(data['close'], window, no_of_stdev=1.5)\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RSI\n",
    "rsi_df = get_rsi(data, window=14)\n",
    "data['rsi'] = pd.Series(data=rsi_df.values, index=data.index)\n",
    "\n",
    "# Drop the NaN values from our data set\n",
    "data.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0    349\n",
      "-1.0    287\n",
      "Name: side, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Compute sides\n",
    "data['side'] = np.nan \n",
    "\n",
    "long_signals = (data['close'] <= data['lower']) \n",
    "short_signals = (data['close'] >= data['upper']) \n",
    "\n",
    "data.loc[long_signals, 'side'] = 1\n",
    "data.loc[short_signals, 'side'] = -1\n",
    "\n",
    "print(data.side.value_counts())\n",
    "\n",
    "# Remove Look ahead bias by lagging the signal\n",
    "data['side'] = data['side'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0    349\n",
      "-1.0    287\n",
      "Name: side, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Save the raw data\n",
    "raw_data = data.copy(deep=True)\n",
    "\n",
    "# Drop the NaN values from our data set\n",
    "data.dropna(axis=0, how='any', inplace=True)\n",
    "print(data.side.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-13 12:52:15.124852 100.0% apply_pt_sl_on_t1 done after 0.0 minutes. Remaining 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Compute daily volatility\n",
    "daily_vol = ml.util.get_daily_vol(close=data['close'], lookback=50)\n",
    "\n",
    "# Apply Symmetric CUSUM Filter and get timestamps for events\n",
    "# Note: Only the CUSUM filter needs a point estimate for volatility\n",
    "cusum_events = ml.filters.cusum_filter(data['close'], threshold=daily_vol.mean() * 0.1)\n",
    "\n",
    "# Compute vertical barrier\n",
    "vertical_barriers = ml.labeling.add_vertical_barrier(t_events=cusum_events, close=data['close'], num_days=1)\n",
    "\n",
    "pt_sl = [0, 2]\n",
    "min_ret = 0.0005\n",
    "\n",
    "triple_barrier_events = ml.labeling.get_events(close=data['close'],\n",
    "                                               t_events=cusum_events,\n",
    "                                               pt_sl=pt_sl,\n",
    "                                               target=daily_vol,\n",
    "                                               min_ret=min_ret,\n",
    "                                               num_threads=2,\n",
    "                                               vertical_barrier_times=vertical_barriers,\n",
    "                                               side_prediction=data['side'])\n",
    "labels = ml.labeling.get_bins(triple_barrier_events, data['close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we make simple financial features based on price data such as momentum, autucorrelation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Returns\n",
    "raw_data['log_ret'] = np.log(raw_data['close']).diff()\n",
    "\n",
    "# Momentum\n",
    "raw_data['mom1'] = raw_data['close'].pct_change(periods=1)\n",
    "raw_data['mom2'] = raw_data['close'].pct_change(periods=2)\n",
    "raw_data['mom3'] = raw_data['close'].pct_change(periods=3)\n",
    "raw_data['mom4'] = raw_data['close'].pct_change(periods=4)\n",
    "raw_data['mom5'] = raw_data['close'].pct_change(periods=5)\n",
    "\n",
    "# Volatility\n",
    "window_stdev = 50\n",
    "raw_data['volatility'] = raw_data['log_ret'].rolling(window=window_stdev, min_periods=window_stdev, center=False).std()\n",
    "\n",
    "# Serial Correlation (Takes about 4 minutes)\n",
    "window_autocorr = 50\n",
    "\n",
    "raw_data['autocorr_1'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=1), raw=False)\n",
    "raw_data['autocorr_2'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=2), raw=False)\n",
    "raw_data['autocorr_3'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=3), raw=False)\n",
    "raw_data['autocorr_4'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=4), raw=False)\n",
    "raw_data['autocorr_5'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=5), raw=False)\n",
    "\n",
    "# Get the various log -t returns\n",
    "raw_data['log_t1'] = raw_data['log_ret'].shift(1)\n",
    "raw_data['log_t2'] = raw_data['log_ret'].shift(2)\n",
    "raw_data['log_t3'] = raw_data['log_ret'].shift(3)\n",
    "raw_data['log_t4'] = raw_data['log_ret'].shift(4)\n",
    "raw_data['log_t5'] = raw_data['log_ret'].shift(5)\n",
    "\n",
    "# Add fast and slow moving averages\n",
    "fast_window = 7\n",
    "slow_window = 15\n",
    "\n",
    "raw_data['fast_mavg'] = raw_data['close'].rolling(window=fast_window, min_periods=fast_window, center=False).mean()\n",
    "raw_data['slow_mavg'] = raw_data['close'].rolling(window=slow_window, min_periods=slow_window, center=False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Trending signals\n",
    "raw_data['sma'] = np.nan\n",
    "\n",
    "long_signals = raw_data['fast_mavg'] >= raw_data['slow_mavg']\n",
    "short_signals = raw_data['fast_mavg'] < raw_data['slow_mavg']\n",
    "raw_data.loc[long_signals, 'sma'] = 1\n",
    "raw_data.loc[short_signals, 'sma'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re compute sides\n",
    "raw_data['side'] = np.nan\n",
    "\n",
    "long_signals = raw_data['close'] <= raw_data['lower'] \n",
    "short_signals = raw_data['close'] >= raw_data['upper'] \n",
    "\n",
    "raw_data.loc[long_signals, 'side'] = 1\n",
    "raw_data.loc[short_signals, 'side'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>cum_vol</th>\n",
       "      <th>cum_dollar</th>\n",
       "      <th>cum_ticks</th>\n",
       "      <th>avg</th>\n",
       "      <th>upper</th>\n",
       "      <th>lower</th>\n",
       "      <th>...</th>\n",
       "      <th>autocorr_4</th>\n",
       "      <th>autocorr_5</th>\n",
       "      <th>log_t1</th>\n",
       "      <th>log_t2</th>\n",
       "      <th>log_t3</th>\n",
       "      <th>log_t4</th>\n",
       "      <th>log_t5</th>\n",
       "      <th>fast_mavg</th>\n",
       "      <th>slow_mavg</th>\n",
       "      <th>sma</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04 14:40:05.559</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 14:43:34.220</th>\n",
       "      <td>1997.75</td>\n",
       "      <td>1999.25</td>\n",
       "      <td>1995.75</td>\n",
       "      <td>1996.50</td>\n",
       "      <td>35065.0</td>\n",
       "      <td>70034780.25</td>\n",
       "      <td>4243.0</td>\n",
       "      <td>2005.024831</td>\n",
       "      <td>2023.794262</td>\n",
       "      <td>1986.255400</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 14:48:09.087</th>\n",
       "      <td>1996.50</td>\n",
       "      <td>1997.00</td>\n",
       "      <td>1991.50</td>\n",
       "      <td>1993.00</td>\n",
       "      <td>35200.0</td>\n",
       "      <td>70188370.25</td>\n",
       "      <td>4463.0</td>\n",
       "      <td>2003.979777</td>\n",
       "      <td>2022.629063</td>\n",
       "      <td>1985.330492</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 14:52:18.754</th>\n",
       "      <td>1993.00</td>\n",
       "      <td>1993.25</td>\n",
       "      <td>1990.50</td>\n",
       "      <td>1992.75</td>\n",
       "      <td>35144.0</td>\n",
       "      <td>70002843.25</td>\n",
       "      <td>4464.0</td>\n",
       "      <td>2003.048247</td>\n",
       "      <td>2021.504820</td>\n",
       "      <td>1984.591674</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 14:57:30.085</th>\n",
       "      <td>1992.75</td>\n",
       "      <td>1999.00</td>\n",
       "      <td>1992.75</td>\n",
       "      <td>1998.00</td>\n",
       "      <td>35221.0</td>\n",
       "      <td>70295761.75</td>\n",
       "      <td>4348.0</td>\n",
       "      <td>2002.647033</td>\n",
       "      <td>2020.447477</td>\n",
       "      <td>1984.846589</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>-0.001755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            open     high      low    close  cum_vol  \\\n",
       "date_time                                                              \n",
       "2016-01-04 14:40:05.559      NaN      NaN      NaN      NaN      NaN   \n",
       "2016-01-04 14:43:34.220  1997.75  1999.25  1995.75  1996.50  35065.0   \n",
       "2016-01-04 14:48:09.087  1996.50  1997.00  1991.50  1993.00  35200.0   \n",
       "2016-01-04 14:52:18.754  1993.00  1993.25  1990.50  1992.75  35144.0   \n",
       "2016-01-04 14:57:30.085  1992.75  1999.00  1992.75  1998.00  35221.0   \n",
       "\n",
       "                          cum_dollar  cum_ticks          avg        upper  \\\n",
       "date_time                                                                   \n",
       "2016-01-04 14:40:05.559          NaN        NaN          NaN          NaN   \n",
       "2016-01-04 14:43:34.220  70034780.25     4243.0  2005.024831  2023.794262   \n",
       "2016-01-04 14:48:09.087  70188370.25     4463.0  2003.979777  2022.629063   \n",
       "2016-01-04 14:52:18.754  70002843.25     4464.0  2003.048247  2021.504820   \n",
       "2016-01-04 14:57:30.085  70295761.75     4348.0  2002.647033  2020.447477   \n",
       "\n",
       "                               lower  ...  autocorr_4  autocorr_5    log_t1  \\\n",
       "date_time                             ...                                     \n",
       "2016-01-04 14:40:05.559          NaN  ...         NaN         NaN       NaN   \n",
       "2016-01-04 14:43:34.220  1986.255400  ...         NaN         NaN       NaN   \n",
       "2016-01-04 14:48:09.087  1985.330492  ...         NaN         NaN       NaN   \n",
       "2016-01-04 14:52:18.754  1984.591674  ...         NaN         NaN -0.001755   \n",
       "2016-01-04 14:57:30.085  1984.846589  ...         NaN         NaN -0.000125   \n",
       "\n",
       "                           log_t2  log_t3  log_t4  log_t5  fast_mavg  \\\n",
       "date_time                                                              \n",
       "2016-01-04 14:40:05.559       NaN     NaN     NaN     NaN        NaN   \n",
       "2016-01-04 14:43:34.220       NaN     NaN     NaN     NaN        NaN   \n",
       "2016-01-04 14:48:09.087       NaN     NaN     NaN     NaN        NaN   \n",
       "2016-01-04 14:52:18.754       NaN     NaN     NaN     NaN        NaN   \n",
       "2016-01-04 14:57:30.085 -0.001755     NaN     NaN     NaN        NaN   \n",
       "\n",
       "                         slow_mavg  sma  \n",
       "date_time                                \n",
       "2016-01-04 14:40:05.559        NaN  NaN  \n",
       "2016-01-04 14:43:34.220        NaN  NaN  \n",
       "2016-01-04 14:48:09.087        NaN  NaN  \n",
       "2016-01-04 14:52:18.754        NaN  NaN  \n",
       "2016-01-04 14:57:30.085        NaN  NaN  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove look ahead bias\n",
    "raw_data = raw_data.shift(1)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features at event dates\n",
    "X = raw_data.loc[labels.index, :]\n",
    "\n",
    "# Drop unwanted columns\n",
    "X.drop(['avg', 'upper', 'lower', 'open', 'high', 'low', 'close', 'cum_vol', 'cum_dollar', 'cum_ticks','fast_mavg', 'slow_mavg',], axis=1, inplace=True)\n",
    "\n",
    "y = labels['bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation and test sets\n",
    "X_training_test = X\n",
    "y_training_test = y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training_test, y_training_test, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    185\n",
       "0    106\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([y_train, X_train], axis=1, join='inner')\n",
    "train_df = train_df.dropna()\n",
    "train_df['bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data\n",
    "y_train = train_df['bin']\n",
    "X_train= train_df.loc[:, train_df.columns != 'bin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SequentiallyBootstrappedBaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we make the random forest classifier considering the uniqueness of samples. we set the average uniqueness of data as the maximum amount of samples in the bootstrap process. If your task is regression type, please check SequentiallyBootstrappedBaggingRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlfinlab.ensemble import SequentiallyBootstrappedBaggingClassifier\n",
    "from mlfinlab.sampling.concurrent import get_av_uniqueness_from_triple_barrier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-13 12:52:27.364022 100.0% num_concurrent_events done after 0.0 minutes. Remaining 0.0 minutes.\n",
      "2020-04-13 12:52:27.463654 100.0% _get_average_uniqueness done after 0.0 minutes. Remaining 0.0 minutes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21987054594884525"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_unique = get_av_uniqueness_from_triple_barrier(triple_barrier_events, raw_data.close, num_threads=3)\n",
    "avgU = av_unique['tW'].mean()\n",
    "avgU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _BaggingClassifier_ with _DecisionTreeClassifier_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _max_samples_: the average uniqueness(_avgU_) between samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_trees = DecisionTreeClassifier(criterion='entropy', max_features='auto', class_weight='balanced')\n",
    "bagging_ensemble = BaggingClassifier(base_estimator=base_trees, n_estimators=1000, max_samples=avgU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = SequentiallyBootstrappedBaggingClassifier(base_estimator=bagging_ensemble,\n",
    "                                                samples_info_sets=triple_barrier_events.loc[X.index, :],\n",
    "                                                price_bars=data.close,\n",
    "                                                max_samples=avgU\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentiallyBootstrappedBaggingClassifier(base_estimator=BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced',\n",
       "                                                                                                                 criterion='entropy',\n",
       "                                                                                                                 max_depth=None,\n",
       "                                                                                                                 max_features='auto',\n",
       "                                                                                                                 max_leaf_nodes=None,\n",
       "                                                                                                                 min_impurity_decrease=0.0,\n",
       "                                                                                                                 min_impurity_split=None,\n",
       "                                                                                                                 min_samples_leaf=1,\n",
       "                                                                                                                 min_samples_split=2,\n",
       "                                                                                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                                                                                 presort=False,\n",
       "                                                                                                                 random...\n",
       "2016-06-24 05:07:07.901 2016-06-26 23:10:23.823000064  0.019140   1.0   0   2\n",
       "2016-06-24 06:02:15.065 2016-06-26 23:10:23.823000064  0.019954   1.0   0   2\n",
       "2016-06-26 23:10:23.823 2016-06-28 19:04:04.158000128  0.019820   1.0   0   2\n",
       "2016-06-27 01:30:01.533 2016-06-28 19:04:04.158000128  0.019446   1.0   0   2\n",
       "2016-06-27 03:30:00.056 2016-06-28 19:04:04.158000128  0.019288   1.0   0   2\n",
       "\n",
       "[364 rows x 5 columns],\n",
       "                                          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train.values.ravel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaggingClassifier on RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _max_samples_: the average uniqueness(_avgU_) between samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_1_tree = RandomForestClassifier(n_estimators=1, criterion='entropy', bootstrap=False, class_weight='balanced_subsample')\n",
    "clf2 = SequentiallyBootstrappedBaggingClassifier(base_estimator=rf_1_tree,\n",
    "                                                 samples_info_sets=triple_barrier_events.loc[X.index, :],\n",
    "                                                 price_bars=data.close,\n",
    "                                                 max_samples=avgU\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentiallyBootstrappedBaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=False,\n",
       "                                                                                class_weight='balanced_subsample',\n",
       "                                                                                criterion='entropy',\n",
       "                                                                                max_depth=None,\n",
       "                                                                                max_features='auto',\n",
       "                                                                                max_leaf_nodes=None,\n",
       "                                                                                min_impurity_decrease=0.0,\n",
       "                                                                                min_impurity_split=None,\n",
       "                                                                                min_samples_leaf=1,\n",
       "                                                                                min_samples_split=2,\n",
       "                                                                                min_weight_fraction_leaf=0.0,\n",
       "                                                                                n_estimators=1,\n",
       "                                                                                n_jobs=None,...\n",
       "2016-06-24 05:07:07.901 2016-06-26 23:10:23.823000064  0.019140   1.0   0   2\n",
       "2016-06-24 06:02:15.065 2016-06-26 23:10:23.823000064  0.019954   1.0   0   2\n",
       "2016-06-26 23:10:23.823 2016-06-28 19:04:04.158000128  0.019820   1.0   0   2\n",
       "2016-06-27 01:30:01.533 2016-06-28 19:04:04.158000128  0.019446   1.0   0   2\n",
       "2016-06-27 03:30:00.056 2016-06-28 19:04:04.158000128  0.019288   1.0   0   2\n",
       "\n",
       "[364 rows x 5 columns],\n",
       "                                          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(X_train, y_train.values.ravel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
